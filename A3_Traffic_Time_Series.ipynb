{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pZlGBYEeV2p6"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import when, col, trim, lower\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.sql.types import DoubleType"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark session\n",
        "# This sets up the entry point to use Spark SQL and ML features\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"TrafficPrediction\") \\\n",
        "    .getOrCreate() # Naming the Spark application"
      ],
      "metadata": {
        "id": "4AHzikfmXTIb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a Spark DataFrame with header and inferSchema to detect data types\n",
        "df = spark.read.csv(\"/content/Traffic.csv\", header=True, inferSchema=True)\n",
        "print(\"Total rows before processing:\", df.count())  # Print number of rows before cleaning\n",
        "\n",
        "# Clean 'Traffic Situation' column by trimming whitespaces and converting to lowercase\n",
        "# This ensures consistent formatting for label mapping\n",
        "df = df.withColumn(\"Traffic Situation\", trim(lower(col(\"Traffic Situation\"))))\n",
        "\n",
        "# Show all distinct values in 'Traffic Situation' to verify consistency\n",
        "df.select(\"Traffic Situation\").distinct().show(truncate=False)\n",
        "\n",
        "# Map text labels to numeric values:\n",
        "# 'low' -> 0, 'moderate' -> 1, 'heavy' -> 2, anything else -> None\n",
        "df = df.withColumn(\n",
        "    \"Traffic Situation\",\n",
        "    when(col(\"Traffic Situation\") == \"low\", 0)\n",
        "    .when(col(\"Traffic Situation\") == \"moderate\", 1)\n",
        "    .when(col(\"Traffic Situation\") == \"heavy\", 2)\n",
        "    .otherwise(None)\n",
        ")\n",
        "\n",
        "# Remove any rows where mapping resulted in null values\n",
        "df = df.dropna(subset=[\"Traffic Situation\"])\n",
        "print(\"Rows after mapping:\", df.count())  # Print number of rows after filtering invalid labels\n",
        "\n",
        "# Convert 'Traffic Situation' column to DoubleType as required for regression model training\n",
        "df = df.withColumn(\"Traffic Situation\", col(\"Traffic Situation\").cast(DoubleType()))\n",
        "\n",
        "# Define feature columns to be used for prediction\n",
        "feature_cols = [\"CarCount\", \"BikeCount\", \"BusCount\", \"TruckCount\", \"Total\"]\n",
        "\n",
        "# Assemble multiple feature columns into a single 'features' vector column (required by MLlib)\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "df = assembler.transform(df)\n",
        "\n",
        "# Randomly split data into training and testing sets (80% train, 20% test)\n",
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
        "print(\"Train rows:\", train_df.count())  # Number of rows in training data\n",
        "print(\"Test rows:\", test_df.count())    # Number of rows in testing data\n",
        "\n",
        "# Initialize Linear Regression model using features and label columns\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Traffic Situation\")\n",
        "model = lr.fit(train_df)  # Train the model using training data\n",
        "\n",
        "# Use trained model to predict traffic situation on test dataset\n",
        "predictions = model.transform(test_df)\n",
        "\n",
        "# Convert continuous predictions to class labels:\n",
        "# < 0.5 => 0 (low), 0.5 - 1.5 => 1 (moderate), >= 1.5 => 2 (heavy)\n",
        "predictions = predictions.withColumn(\n",
        "    \"Predicted Traffic Situation\",\n",
        "    when(col(\"prediction\") < 0.5, 0)\n",
        "    .when((col(\"prediction\") >= 0.5) & (col(\"prediction\") < 1.5), 1)\n",
        "    .otherwise(2)\n",
        ")\n",
        "\n",
        "# Display actual vs predicted traffic situations along with feature vector\n",
        "predictions.select(\"features\", \"Traffic Situation\", \"prediction\", \"Predicted Traffic Situation\").show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIhhJev_XKt6",
        "outputId": "a74e711f-89c8-4a29-8779-6e69d2940af8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows before processing: 2976\n",
            "+-----------------+\n",
            "|Traffic Situation|\n",
            "+-----------------+\n",
            "|low              |\n",
            "|normal           |\n",
            "|high             |\n",
            "|heavy            |\n",
            "+-----------------+\n",
            "\n",
            "Rows after mapping: 986\n",
            "Train rows: 827\n",
            "Test rows: 159\n",
            "+---------------------------+-----------------+--------------------+---------------------------+\n",
            "|features                   |Traffic Situation|prediction          |Predicted Traffic Situation|\n",
            "+---------------------------+-----------------+--------------------+---------------------------+\n",
            "|[10.0,1.0,13.0,7.0,31.0]   |0.0              |-0.14655629604544473|0                          |\n",
            "|[80.0,6.0,12.0,6.0,104.0]  |0.0              |0.7002160159603095  |1                          |\n",
            "|[18.0,1.0,0.0,10.0,29.0]   |0.0              |-0.27220584657717933|0                          |\n",
            "|[177.0,56.0,12.0,4.0,249.0]|2.0              |2.158581742012165   |2                          |\n",
            "|[12.0,1.0,0.0,12.0,25.0]   |0.0              |-0.2979712428880069 |0                          |\n",
            "|[160.0,47.0,30.0,3.0,240.0]|2.0              |2.2794922567318134  |2                          |\n",
            "|[144.0,44.0,16.0,3.0,207.0]|2.0              |1.7443853859838807  |2                          |\n",
            "|[25.0,12.0,13.0,5.0,55.0]  |0.0              |0.05859437139183743 |0                          |\n",
            "|[180.0,48.0,17.0,2.0,247.0]|2.0              |2.211599736035596   |2                          |\n",
            "|[133.0,56.0,25.0,2.0,216.0]|2.0              |1.8647275012172644  |2                          |\n",
            "+---------------------------+-----------------+--------------------+---------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop the Spark session after completion to free up resources\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "X9li4HCfXX4O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ðŸ“Œ Concept Notes\n",
        "ðŸ”· 1. PySpark\n",
        "Distributed computing framework for handling big data.\n",
        "\n",
        "SparkSession: Entry point to use DataFrame and MLlib.\n",
        "\n",
        "ðŸ”· 2. Data Preprocessing\n",
        "trim() & lower(): Clean string columns for consistency.\n",
        "\n",
        "when() & col(): Used for conditional value transformation.\n",
        "\n",
        "dropna(): Removes rows with missing data.\n",
        "\n",
        "ðŸ”· 3. Label Encoding\n",
        "String categories converted to numbers:\n",
        "\n",
        "\"low\" â†’ 0\n",
        "\n",
        "\"moderate\" / \"normal\" â†’ 1\n",
        "\n",
        "\"heavy\" / \"high\" â†’ 2\n",
        "\n",
        "Required for ML algorithms which work with numerical data only.\n",
        "\n",
        "ðŸ”· 4. VectorAssembler\n",
        "Combines multiple feature columns into a single vector.\n",
        "\n",
        "Required input format for Spark MLlib models.\n",
        "\n",
        "ðŸ”· 5. Linear Regression (MLlib)\n",
        "Supervised learning algorithm.\n",
        "\n",
        "Used here to predict numeric traffic levels (0, 1, 2).\n",
        "\n",
        "featuresCol: Input features vector.\n",
        "\n",
        "labelCol: Target variable (Traffic Situation).\n",
        "\n",
        "ðŸ”· 6. Prediction Mapping\n",
        "Model prediction is a continuous value.\n",
        "\n",
        "Mapped to categories using thresholding:\n",
        "\n",
        "< 0.5 â†’ 0 (Low traffic)\n",
        "\n",
        "0.5 to <1.5 â†’ 1 (Moderate traffic)\n",
        "\n",
        ">= 1.5 â†’ 2 (Heavy traffic)\n",
        "\n",
        "ðŸ“Š Dataset Description\n",
        "\n",
        "Column Name\tDescription\n",
        "CarCount\tNumber of cars observed at a point\n",
        "BikeCount\tNumber of bikes observed\n",
        "BusCount\tNumber of buses observed\n",
        "TruckCount\tNumber of trucks observed\n",
        "Total\tTotal vehicles (sum of above)\n",
        "Traffic Situation\tTraffic level (low / normal / high / etc.)\n",
        "ðŸŸ¨ Traffic Situation Labels\n",
        "\n",
        "Label\tMeaning\n",
        "0\tLow Traffic\n",
        "1\tModerate / Normal Traffic\n",
        "2\tHeavy / High Traffic\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "collapsed": true,
        "id": "lyO6hOOEY08d",
        "outputId": "b98cd962-806f-4b34-fe46-c1cf49a38dc1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nðŸ“Œ Concept Notes\\nðŸ”· 1. PySpark\\nDistributed computing framework for handling big data.\\n\\nSparkSession: Entry point to use DataFrame and MLlib.\\n\\nðŸ”· 2. Data Preprocessing\\ntrim() & lower(): Clean string columns for consistency.\\n\\nwhen() & col(): Used for conditional value transformation.\\n\\ndropna(): Removes rows with missing data.\\n\\nðŸ”· 3. Label Encoding\\nString categories converted to numbers:\\n\\n\"low\" â†’ 0\\n\\n\"moderate\" / \"normal\" â†’ 1\\n\\n\"heavy\" / \"high\" â†’ 2\\n\\nRequired for ML algorithms which work with numerical data only.\\n\\nðŸ”· 4. VectorAssembler\\nCombines multiple feature columns into a single vector.\\n\\nRequired input format for Spark MLlib models.\\n\\nðŸ”· 5. Linear Regression (MLlib)\\nSupervised learning algorithm.\\n\\nUsed here to predict numeric traffic levels (0, 1, 2).\\n\\nfeaturesCol: Input features vector.\\n\\nlabelCol: Target variable (Traffic Situation).\\n\\nðŸ”· 6. Prediction Mapping\\nModel prediction is a continuous value.\\n\\nMapped to categories using thresholding:\\n\\n< 0.5 â†’ 0 (Low traffic)\\n\\n0.5 to <1.5 â†’ 1 (Moderate traffic)\\n\\n>= 1.5 â†’ 2 (Heavy traffic)\\n\\nðŸ“Š Dataset Description\\n\\nColumn Name\\tDescription\\nCarCount\\tNumber of cars observed at a point\\nBikeCount\\tNumber of bikes observed\\nBusCount\\tNumber of buses observed\\nTruckCount\\tNumber of trucks observed\\nTotal\\tTotal vehicles (sum of above)\\nTraffic Situation\\tTraffic level (low / normal / high / etc.)\\nðŸŸ¨ Traffic Situation Labels\\n\\nLabel\\tMeaning\\n0\\tLow Traffic\\n1\\tModerate / Normal Traffic\\n2\\tHeavy / High Traffic\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "VIVA QUESTIONS\n",
        "ðŸ”¹ Basic Questions\n",
        "1. What is PySpark?\n",
        "â†’ PySpark is the Python API for Apache Spark, used for big data processing and machine learning in a distributed environment.\n",
        "\n",
        "2. What is a SparkSession?\n",
        "â†’ SparkSession is the entry point to Spark functionalities, including DataFrame and MLlib operations.\n",
        "\n",
        "3. What is the purpose of VectorAssembler?\n",
        "â†’ It combines multiple feature columns into a single vector column required by MLlib models.\n",
        "\n",
        "ðŸ”¹ Data Preprocessing\n",
        "4. Why did you use trim() and lower() on the 'Traffic Situation' column?\n",
        "â†’ To remove extra spaces and convert to lowercase for consistent string matching.\n",
        "\n",
        "5. Why did we map traffic labels to numbers?\n",
        "â†’ ML models in PySpark require numerical input, so categorical labels must be encoded.\n",
        "\n",
        "6. Why was dropna() used?\n",
        "â†’ To remove rows with missing or unmapped traffic labels.\n",
        "\n",
        "ðŸ”¹ Model and Training\n",
        "7. Why did you choose Linear Regression for this task?\n",
        "â†’ It was used to predict traffic level as a continuous variable, later mapped to categories.\n",
        "\n",
        "8. What is the role of labelCol and featuresCol in MLlib?\n",
        "â†’ labelCol is the target column; featuresCol contains the input features as a vector.\n",
        "\n",
        "9. What type of learning is this?\n",
        "â†’ Supervised learning (Regression).\n",
        "\n",
        "ðŸ”¹ Output Interpretation\n",
        "10. What does the prediction column represent?\n",
        "â†’ It gives the continuous output from the linear regression model.\n",
        "\n",
        "11. What do 0, 1, and 2 mean in 'Predicted Traffic Situation'?\n",
        "â†’\n",
        "\n",
        "0 â†’ Low Traffic\n",
        "\n",
        "1 â†’ Moderate/Normal Traffic\n",
        "\n",
        "2 â†’ Heavy/High Traffic\n",
        "\n",
        "12. How did you map continuous predictions to categories?\n",
        "â†’ Using threshold ranges:\n",
        "\n",
        "< 0.5 â†’ 0\n",
        "\n",
        "0.5 to <1.5 â†’ 1\n",
        "\n",
        ">= 1.5 â†’ 2\n",
        "\n",
        "ðŸ”¹ Additional/Conceptual\n",
        "13. Why not use classification instead of regression?\n",
        "â†’ Regression was used here for simplicity. Classification could also be used for better label prediction.\n",
        "\n",
        "14. Can this model be improved? How?\n",
        "â†’ Yes, by using classification algorithms (like Decision Tree, Random Forest), better feature selection, or hyperparameter tuning.\n",
        "\n",
        "15. What are the advantages of using Spark MLlib?\n",
        "â†’ It handles large datasets efficiently using distributed computing, supports pipelines, and is scalable.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KB_Ikrd1ZUyz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}