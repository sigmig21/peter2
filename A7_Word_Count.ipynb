{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DL3jxVpAjPmj"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules from PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode, split, col"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Spark session named \"WordCount\"\n",
        "spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()\n",
        "\n",
        "# ------------------------------------------\n",
        "# If a text file was used as input, this line would load it as a DataFrame:\n",
        "# df = spark.read.text(\"/content/drive/MyDrive/word_count.txt\")\n",
        "# ------------------------------------------\n",
        "\n",
        "# Instead of reading from a file, we create a DataFrame from a hardcoded input string\n",
        "# The DataFrame will have one column named \"value\" and one row containing the sentence\n",
        "df = spark.createDataFrame([(\"I love you. You are the love of my life\",)], [\"value\"])\n",
        "\n",
        "# Perform the word count:\n",
        "word_counts = (\n",
        "    # Split the sentence into words using whitespace and explode into multiple rows (one word per row)\n",
        "    df.select(explode(split(col(\"value\"), \"\\\\s+\")).alias(\"word\"))\n",
        "    # Group by each unique word\n",
        "    .groupBy(\"word\")\n",
        "    # Count the occurrences of each word\n",
        "    .count()\n",
        "    # Order the results in descending order of count\n",
        "    .orderBy(col(\"count\").desc())\n",
        ")\n",
        "\n",
        "# Show the final word count result\n",
        "word_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDaeRSnijguT",
        "outputId": "e0ccbc2b-d44a-4da1-b4ff-2c20554ab85b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|word|count|\n",
            "+----+-----+\n",
            "|love|    2|\n",
            "|you.|    1|\n",
            "|life|    1|\n",
            "| You|    1|\n",
            "| the|    1|\n",
            "|  my|    1|\n",
            "| are|    1|\n",
            "|  of|    1|\n",
            "|   I|    1|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop the Spark session to release resources\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "DfLMaJGXjg35"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ðŸ”¹ 1. PySpark\n",
        "PySpark is the Python API for Apache Spark, an open-source distributed computing framework for big data processing.\n",
        "\n",
        "It enables scalable data analysis using Python.\n",
        "\n",
        "This creates a DataFrame with one row and one column (value) containing the input string.\n",
        "\n",
        "Useful for testing logic without loading an external file.\n",
        "\n",
        "ðŸ”¹ 4. Functions from pyspark.sql.functions\n",
        "\n",
        "from pyspark.sql.functions import explode, split, col\n",
        "These are transform functions used in DataFrame operations:\n",
        "\n",
        "âœ… split(col(\"value\"), \"\\\\s+\")\n",
        "Splits the string in value column by one or more whitespace characters (\\\\s+ is a regex for space, tab, etc.).\n",
        "\n",
        "Returns an array of words.\n",
        "\n",
        "âœ… explode(...)\n",
        "Takes an array column (like list of words) and returns a new row for each element in the array.\n",
        "\n",
        "So, one sentence becomes multiple rows with one word each.\n",
        "\n",
        "âœ… col(\"column_name\")\n",
        "Refers to a column in a DataFrame by name.\n",
        "\n",
        "Used for selecting or manipulating DataFrame columns.\n",
        "\n",
        "ðŸ”¹ 5. DataFrame Operations\n",
        "âœ… .select(...)\n",
        "Selects specific columns from the DataFrame.\n",
        "\n",
        "In this case, selects and aliases exploded words as \"word\".\n",
        "\n",
        "âœ… .groupBy(\"word\").count()\n",
        "Groups rows by the \"word\" column.\n",
        "\n",
        ".count() computes how many times each word occurs.\n",
        "\n",
        "âœ… .orderBy(col(\"count\").desc())\n",
        "Orders the word counts in descending order, so most frequent words appear first.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "5B2PhPYelIiH",
        "outputId": "7d68936e-c375-48f5-968e-88f9b5242ae1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nðŸ”¹ 1. PySpark\\nPySpark is the Python API for Apache Spark, an open-source distributed computing framework for big data processing.\\n\\nIt enables scalable data analysis using Python.\\n\\nThis creates a DataFrame with one row and one column (value) containing the input string.\\n\\nUseful for testing logic without loading an external file.\\n\\nðŸ”¹ 4. Functions from pyspark.sql.functions\\n\\nfrom pyspark.sql.functions import explode, split, col\\nThese are transform functions used in DataFrame operations:\\n\\nâœ… split(col(\"value\"), \"\\\\s+\")\\nSplits the string in value column by one or more whitespace characters (\\\\s+ is a regex for space, tab, etc.).\\n\\nReturns an array of words.\\n\\nâœ… explode(...)\\nTakes an array column (like list of words) and returns a new row for each element in the array.\\n\\nSo, one sentence becomes multiple rows with one word each.\\n\\nâœ… col(\"column_name\")\\nRefers to a column in a DataFrame by name.\\n\\nUsed for selecting or manipulating DataFrame columns.\\n\\nðŸ”¹ 5. DataFrame Operations\\nâœ… .select(...)\\nSelects specific columns from the DataFrame.\\n\\nIn this case, selects and aliases exploded words as \"word\".\\n\\nâœ… .groupBy(\"word\").count()\\nGroups rows by the \"word\" column.\\n\\n.count() computes how many times each word occurs.\\n\\nâœ… .orderBy(col(\"count\").desc())\\nOrders the word counts in descending order, so most frequent words appear first.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}